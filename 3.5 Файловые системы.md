## Ответы к заданию: "Операционные системы. Лекция 2"

#### 1. Узнайте о sparse-файлах (разряженных).
Выполнено


#### 2. Могут ли файлы, являющиеся жёсткой ссылкой на один объект, иметь разные права доступа и владельца? Почему?
Нет не могут, т.к. при жесткие ссылки ссылаются на один и тот же индексный дескриптор (inod), т.е. тот же дескриптор что и уфайла с которого создали эту жесткую ссылку.

#### 3. Сделайте vagrant destroy на имеющийся инстанс Ubuntu. Замените содержимое Vagrantfile следующим..
Эта конфигурация создаст новую виртуальную машину с двумя дополнительными неразмеченными дисками по 2,5 Гб.

Выполнено.

```
vagrant@sysadm-fs:~$ lsblk
NAME                      MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
loop0                       7:0    0 67.8M  1 loop /snap/lxd/22753
loop1                       7:1    0   47M  1 loop /snap/snapd/16292
loop2                       7:2    0   62M  1 loop /snap/core20/1611
sda                         8:0    0   64G  0 disk
├─sda1                      8:1    0    1M  0 part
├─sda2                      8:2    0    2G  0 part /boot
└─sda3                      8:3    0   62G  0 part
  └─ubuntu--vg-ubuntu--lv 253:0    0   31G  0 lvm  /
sdb                         8:16   0  2.5G  0 disk
sdc                         8:32   0  2.5G  0 disk
```

#### 4. Используя fdisk, разбейте первый диск на два раздела: 2 Гб и оставшееся пространство.

```
Disk /dev/sdb: 2.51 GiB, 2684354560 bytes, 5242880 sectors
Disk model: VBOX HARDDISK
Units: sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disklabel type: dos
Disk identifier: 0xa6998c40

Device     Boot   Start     End Sectors  Size Id Type
/dev/sdb1          2048 4196351 4194304    2G 83 Linux
/dev/sdb2       4196352 5242879 1046528  511M 83 Linux
```


#### 5. спользуя sfdisk, перенесите эту таблицу разделов на второй диск.

```
root@sysadm-fs: sfdisk -d /dev/sdb | sfdisk /dev/sdc
```

#### 6. Соберите mdadm RAID1 на паре разделов 2 Гб.

```
mdadm --create --verbose /dev/md1 --level=1 --raid-devices=2 /dev/sdb1 /dev/sdc1
```

#### 7. Соберите mdadm RAID0 на второй паре маленьких разделов.

```
mdadm --create --verbose /dev/md0 --level=0 --raid-devices=2 /dev/sdb2 /dev/sdc2
```

```
root@sysadm-fs:~# cat /proc/mdstat
Personalities : [linear] [multipath] [raid0] [raid1] [raid6] [raid5] [raid4] [raid10]
md0 : active raid0 sdc2[1] sdb2[0]
      1042432 blocks super 1.2 512k chunks

md1 : active raid1 sdc1[1] sdb1[0]
      2094080 blocks super 1.2 [2/2] [UU]
```

#### 8. Создайте два независимых PV на получившихся md-устройствах.

```
vagrant@sysadm-fs:~$ sudo pvcreate /dev/md0 /dev/md1
  Physical volume "/dev/md0" successfully created.
  Physical volume "/dev/md1" successfully created.
```

#### 9. Создайте общую volume-group на этих двух PV.

```
root@sysadm-fs:~# vgcreate VG1 /dev/md0 /dev/md1
Volume group "VG1" successfully created

root@sysadm-fs:~# vgscan
Found volume group "ubuntu-vg" using metadata type lvm2
Found volume group "VG1" using metadata type lvm2
```

#### 10. Создайте LV размером 100 Мб, указав его расположение на PV с RAID0.

```
root@sysadm-fs:~# lvcreate -n LV1 -L 100M VG1 /dev/md0
  Logical volume "LV1" created.
```

#### 11. Создайте mkfs.ext4 ФС на получившемся LV

```
root@sysadm-fs:/tmp/dir# mkfs.ext4 /dev/VG1/LV1
mke2fs 1.45.5 (07-Jan-2020)
Creating filesystem with 25600 4k blocks and 25600 inodes

Allocating group tables: done
Writing inode tables: done
Creating journal (1024 blocks): done
Writing superblocks and filesystem accounting information: done
```


#### 12. Смонтируйте этот раздел в любую директорию, например, /tmp/new.
```
root@sysadm-fs:/tmp# mount /dev/VG1/LV1 /tmp/new
```

#### 13. Поместите туда тестовый файл, например, wget https://mirror.yandex.ru/ubuntu/ls-lR.gz -O /tmp/new/test.gz

```
root@sysadm-fs:/tmp/new# wget https://mirror.yandex.ru/ubuntu/ls-lR.gz -O /tmp/new/test.gz
--2023-04-01 16:01:18--  https://mirror.yandex.ru/ubuntu/ls-lR.gz
Resolving mirror.yandex.ru (mirror.yandex.ru)... 213.180.204.183, 2a02:6b8::183
Connecting to mirror.yandex.ru (mirror.yandex.ru)|213.180.204.183|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 24673710 (24M) [application/octet-stream]
Saving to: ‘/tmp/new/test.gz’

/tmp/new/test.gz               100%[====================================================>]  23.53M   259KB/s    in 4m 57s

2023-04-01 16:06:18 (81.1 KB/s) - ‘/tmp/new/test.gz’ saved [24673710/24673710]
```

#### 14. Прикрепите вывод lsblk.

```
root@sysadm-fs:/tmp/new# lsblk
NAME                      MAJ:MIN RM  SIZE RO TYPE  MOUNTPOINT
loop0                       7:0    0   62M  1 loop  /snap/core20/1611
loop1                       7:1    0 91.9M  1 loop  /snap/lxd/24061
loop2                       7:2    0 49.9M  1 loop  /snap/snapd/18596
loop3                       7:3    0 67.8M  1 loop  /snap/lxd/22753
loop4                       7:4    0 63.3M  1 loop  /snap/core20/1852
sda                         8:0    0   64G  0 disk
├─sda1                      8:1    0    1M  0 part
├─sda2                      8:2    0    2G  0 part  /boot
└─sda3                      8:3    0   62G  0 part
  └─ubuntu--vg-ubuntu--lv 253:0    0   31G  0 lvm   /
sdb                         8:16   0  2.5G  0 disk
├─sdb1                      8:17   0    2G  0 part
│ └─md1                     9:1    0    2G  0 raid1
└─sdb2                      8:18   0  511M  0 part
  └─md0                     9:0    0 1018M  0 raid0
    └─VG1-LV1             253:1    0  100M  0 lvm   /tmp/new
sdc                         8:32   0  2.5G  0 disk
├─sdc1                      8:33   0    2G  0 part
│ └─md1                     9:1    0    2G  0 raid1
└─sdc2                      8:34   0  511M  0 part
  └─md0                     9:0    0 1018M  0 raid0
    └─VG1-LV1             253:1    0  100M  0 lvm   /tmp/new
```

#### 15. Протестируйте целостность файла
```
root@sysadm-fs:/tmp/new# gzip -t /tmp/new/test.gz
root@sysadm-fs:/tmp/new# echo $?
0
```

#### 16. Используя pvmove, переместите содержимое PV с RAID0 на RAID1.
```
root@sysadm-fs:/tmp/new# pvmove /dev/md0 /dev/md1
File descriptor 4 (pipe:[33475]) leaked on pvmove invocation. Parent PID 1780: bash
File descriptor 5 (pipe:[33475]) leaked on pvmove invocation. Parent PID 1780: bash
File descriptor 9 (pipe:[33478]) leaked on pvmove invocation. Parent PID 1780: bash
  /dev/md0: Moved: 100.00%
```

```
root@sysadm-fs:/tmp# lsblk
NAME                      MAJ:MIN RM  SIZE RO TYPE  MOUNTPOINT
loop0                       7:0    0   62M  1 loop  /snap/core20/1611
loop1                       7:1    0 91.9M  1 loop  /snap/lxd/24061
loop2                       7:2    0 49.9M  1 loop  /snap/snapd/18596
loop3                       7:3    0 67.8M  1 loop  /snap/lxd/22753
loop4                       7:4    0 63.3M  1 loop  /snap/core20/1852
sda                         8:0    0   64G  0 disk
├─sda1                      8:1    0    1M  0 part
├─sda2                      8:2    0    2G  0 part  /boot
└─sda3                      8:3    0   62G  0 part
  └─ubuntu--vg-ubuntu--lv 253:0    0   31G  0 lvm   /
sdb                         8:16   0  2.5G  0 disk
├─sdb1                      8:17   0    2G  0 part
│ └─md1                     9:1    0    2G  0 raid1
│   └─VG1-LV1             253:1    0  100M  0 lvm   /tmp/new
└─sdb2                      8:18   0  511M  0 part
  └─md0                     9:0    0 1018M  0 raid0
sdc                         8:32   0  2.5G  0 disk
├─sdc1                      8:33   0    2G  0 part
│ └─md1                     9:1    0    2G  0 raid1
│   └─VG1-LV1             253:1    0  100M  0 lvm   /tmp/new
└─sdc2                      8:34   0  511M  0 part
  └─md0                     9:0    0 1018M  0 raid0
```

#### 17. Сделайте --fail на устройство в вашем RAID1 md.
```
root@sysadm-fs:/tmp# mdadm /dev/md1 --fail /dev/sdb1
mdadm: set /dev/sdb1 faulty in /dev/md1
```

#### 18. Подтвердите выводом dmesg, что RAID1 работает в деградированном состояни

```
root@sysadm-fs:/tmp# dmesg | grep md1
[    2.919440] md/raid1:md1: active with 2 out of 2 mirrors
[    2.919959] md1: detected capacity change from 0 to 2144337920
[16473.773667] md/raid1:md1: Disk failure on sdb1, disabling device.
               md/raid1:md1: Operation continuing on 1 devices.
```


#### 19. Протестируйте целостность файла — он должен быть доступен несмотря на «сбойный» диск

```
root@sysadm-fs:/tmp# gzip -t /tmp/new/test.gz
root@sysadm-fs:/tmp# echo $?
0
```




